{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae0c0b0-3a40-4abf-b39f-9084bfa746f6",
   "metadata": {},
   "source": [
    "# Wherobots Astronomer Workshop Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce308a-0c2a-4d50-85a5-20261c8f7fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:11:27.806163Z",
     "iopub.status.busy": "2026-01-19T17:11:27.806026Z",
     "iopub.status.idle": "2026-01-19T17:11:27.809120Z",
     "shell.execute_reply": "2026-01-19T17:11:27.808601Z",
     "shell.execute_reply.started": "2026-01-19T17:11:27.806147Z"
    }
   },
   "outputs": [],
   "source": [
    "# User input\n",
    "CATALOG=\"org_catalog\"\n",
    "DATABASE=\"workshop\"\n",
    "US_POSTCODE = \"73034\"\n",
    "\n",
    "\n",
    "# based on Dag run date\n",
    "END_DATE = \"2026-01-19\"\n",
    "\n",
    "# set on our end\n",
    "lookback_months = 3\n",
    "COUNTRY = \"US\"\n",
    "\n",
    "# from within Airflow this will be passed in as CLI args to the run_python dict\n",
    "# and retrieved via argparse: \n",
    "\n",
    "# import argparse\n",
    "# from datetime import datetime\n",
    "# from dateutil.relativedelta import relativedelta\n",
    "# from pyspark.sql.functions import expr, col, to_timestamp\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--catalog', type=str, default='org_catalog')\n",
    "# parser.add_argument('--database', type=str, default='workshop')\n",
    "# parser.add_argument('--postcode', type=str, default='75001')\n",
    "# parser.add_argument('--country', type=str, default='US')\n",
    "# parser.add_argument('--end-date', type=str, default=None)\n",
    "# parser.add_argument('--lookback-months', type=int, default=3)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# CATALOG = args.catalog\n",
    "# DATABASE = args.database\n",
    "# US_POSTCODE = args.postcode\n",
    "# COUNTRY = args.country\n",
    "# LOOKBACK_MONTHS = args.lookback_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25848a7f-fd98-45fa-bda9-25e77d813d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:11:28.480842Z",
     "iopub.status.busy": "2026-01-19T17:11:28.480685Z",
     "iopub.status.idle": "2026-01-19T17:11:29.647426Z",
     "shell.execute_reply": "2026-01-19T17:11:29.646709Z",
     "shell.execute_reply.started": "2026-01-19T17:11:28.480826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "from sedona.spark import *\n",
    "from pyspark.sql.functions import expr, col, to_timestamp\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c3c9e-bae9-4be8-99e7-5bba62811419",
   "metadata": {},
   "source": [
    "## Set up an Apache Sedona context\n",
    "\n",
    "The context, `sedona`, is the machine that runs in the Wherobots Cloud compute environment. To connect to the SWDI data on AWS, \n",
    "we add anonymous S3 access credentials when we call `SedonaContext.builder().getOrCreate()`. \n",
    "You can read [our documentation](https://docs.wherobots.com/latest/develop/notebook-management/notebook-instance-management/) \n",
    "about how to further configure the Sedona context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7609e-71a2-44a0-a719-a2ee1bac4bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:11:33.091577Z",
     "iopub.status.busy": "2026-01-19T17:11:33.091198Z",
     "iopub.status.idle": "2026-01-19T17:11:58.736572Z",
     "shell.execute_reply": "2026-01-19T17:11:58.735735Z",
     "shell.execute_reply.started": "2026-01-19T17:11:33.091557Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sedona\n",
    "except NameError:\n",
    "    config = SedonaContext.builder() \\\n",
    "    .config(\"fs.s3a.bucket.noaa-swdi-pds.aws.credentials.provider\",\"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.bucket.noaa-swdi-pds.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\") \\\n",
    "    .getOrCreate()\n",
    "    sedona = SedonaContext.create(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6d025-7ec8-49c1-ac4a-e415e443b593",
   "metadata": {},
   "source": [
    "## Setup DB\n",
    "\n",
    "-> separate WherobotsSqlOperator s for each table in the Dag as a task group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77098e3a-84e8-4f00-b5f6-7ebce593e03b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:12:00.256695Z",
     "iopub.status.busy": "2026-01-19T17:12:00.256466Z",
     "iopub.status.idle": "2026-01-19T17:12:02.521362Z",
     "shell.execute_reply": "2026-01-19T17:12:02.520777Z",
     "shell.execute_reply.started": "2026-01-19T17:12:00.256677Z"
    }
   },
   "outputs": [],
   "source": [
    "sedona.sql(f\"CREATE DATABASE IF NOT EXISTS {CATALOG}.{DATABASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b18cc0-5249-4437-af40-aebbec03a244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:12:03.500233Z",
     "iopub.status.busy": "2026-01-19T17:12:03.500023Z",
     "iopub.status.idle": "2026-01-19T17:12:06.408668Z",
     "shell.execute_reply": "2026-01-19T17:12:06.407898Z",
     "shell.execute_reply.started": "2026-01-19T17:12:03.500216Z"
    }
   },
   "outputs": [],
   "source": [
    "sedona.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{DATABASE}.hail_raw (\n",
    "        ZTIME TIMESTAMP,\n",
    "        LON STRING,\n",
    "        LAT STRING,\n",
    "        WSR_ID STRING,\n",
    "        CELL_ID STRING,\n",
    "        RANGE STRING,\n",
    "        AZIMUTH STRING,\n",
    "        SEVPROB STRING,\n",
    "        PROB STRING,\n",
    "        MAXSIZE STRING,\n",
    "        geometry GEOMETRY\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{DATABASE}.postcode_areas (\n",
    "        postcode STRING,\n",
    "        country STRING,\n",
    "        area GEOMETRY,\n",
    "        created_at TIMESTAMP\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{DATABASE}.state_boundary (\n",
    "        id STRING,\n",
    "        state_name STRING,\n",
    "        state_code STRING,\n",
    "        geometry GEOMETRY\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{DATABASE}.hail_state (\n",
    "        ZTIME TIMESTAMP,\n",
    "        LON STRING,\n",
    "        LAT STRING,\n",
    "        WSR_ID STRING,\n",
    "        CELL_ID STRING,\n",
    "        RANGE STRING,\n",
    "        AZIMUTH STRING,\n",
    "        SEVPROB STRING,\n",
    "        PROB STRING,\n",
    "        MAXSIZE STRING,\n",
    "        geometry GEOMETRY,\n",
    "        state_code STRING\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{DATABASE}.hail_neighborhood (\n",
    "        ZTIME TIMESTAMP,\n",
    "        LON STRING,\n",
    "        LAT STRING,\n",
    "        WSR_ID STRING,\n",
    "        CELL_ID STRING,\n",
    "        RANGE STRING,\n",
    "        AZIMUTH STRING,\n",
    "        SEVPROB STRING,\n",
    "        PROB STRING,\n",
    "        MAXSIZE STRING,\n",
    "        geometry GEOMETRY,\n",
    "        postcode STRING\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{DATABASE}.risk_comparison (\n",
    "        area_type STRING,\n",
    "        area_id STRING,\n",
    "        event_count BIGINT,\n",
    "        events_per_sqmi DOUBLE,\n",
    "        avg_hail_size DOUBLE,\n",
    "        max_hail_size DOUBLE,\n",
    "        avg_severe_prob DOUBLE,\n",
    "        avg_hail_prob DOUBLE,\n",
    "        damaging_events BIGINT,\n",
    "        damaging_per_sqmi DOUBLE,\n",
    "        high_risk_events BIGINT,\n",
    "        high_risk_per_sqmi DOUBLE,\n",
    "        area_sqmi DOUBLE,\n",
    "        updated_at TIMESTAMP\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a8b3a-c332-4b0b-ba73-32f9af346f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T13:53:56.742294Z",
     "iopub.status.busy": "2026-01-19T13:53:56.742089Z",
     "iopub.status.idle": "2026-01-19T13:53:56.744905Z",
     "shell.execute_reply": "2026-01-19T13:53:56.744212Z",
     "shell.execute_reply.started": "2026-01-19T13:53:56.742279Z"
    }
   },
   "source": [
    "### Cleanup\n",
    "\n",
    "This will be a separate Dag that resets everything to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b4fa0-9b84-4c70-b7ce-d7c805df89eb",
   "metadata": {
    "execution": {
     "execution_failed": "2026-01-19T17:11:15.324Z"
    }
   },
   "outputs": [],
   "source": [
    "## Delete everything\n",
    "# sedona.sql(f\"SHOW TABLES IN {CATALOG}.{DATABASE}\").show(truncate=False)\n",
    "\n",
    "# tables = sedona.sql(f\"SHOW TABLES IN {CATALOG}.{DATABASE}\").collect()\n",
    "\n",
    "# for table in tables:\n",
    "#     table_name = table['tableName']\n",
    "#     print(f\"Dropping {table_name}...\")\n",
    "#     sedona.sql(f\"DROP TABLE IF EXISTS org_catalog.workshop.{table_name}\")\n",
    "\n",
    "# sedona.sql(f\"SHOW TABLES IN {CATALOG}.{DATABASE}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6016cfa-4537-4ac2-aa6e-ba74adcff057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:12:55.163985Z",
     "iopub.status.busy": "2026-01-19T17:12:55.163814Z",
     "iopub.status.idle": "2026-01-19T17:12:55.166335Z",
     "shell.execute_reply": "2026-01-19T17:12:55.165841Z",
     "shell.execute_reply.started": "2026-01-19T17:12:55.163969Z"
    }
   },
   "outputs": [],
   "source": [
    "## Empty everything but hail_raw\n",
    "# tables = sedona.sql(f\"SHOW TABLES IN {CATALOG}.{DATABASE}\").collect()\n",
    "\n",
    "# for table in tables:\n",
    "#     table_name = table['tableName']\n",
    "#     sedona.sql(f\"DELETE FROM {CATALOG}.{DATABASE}.{table_name}\")\n",
    "\n",
    "# sedona.sql(f\"\"\"\n",
    "#     SELECT 'hail_state', COUNT(*) FROM {CATALOG}.{DATABASE}.hail_state\n",
    "#     UNION ALL SELECT 'hail_neighborhood', COUNT(*) FROM {CATALOG}.{DATABASE}.hail_neighborhood\n",
    "#     UNION ALL SELECT 'postcode_areas', COUNT(*) FROM {CATALOG}.{DATABASE}.postcode_areas\n",
    "#     UNION ALL SELECT 'state_boundary', COUNT(*) FROM {CATALOG}.{DATABASE}.state_boundary\n",
    "#     UNION ALL SELECT 'risk_comparison', COUNT(*) FROM {CATALOG}.{DATABASE}.risk_comparison\n",
    "# \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8c5da-2359-4f49-9717-06acd8e7fc24",
   "metadata": {},
   "source": [
    "## Load Hail data past 3 months \n",
    "\n",
    "Dates templated by Airflow\n",
    "\n",
    "Available years: 1995 - 2025\n",
    "\n",
    "Could run this Dag weekly?\n",
    "\n",
    "Question: will it be possible to pass information into the script? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceae4fa-fb72-43c8-bf4b-ca30b8a0aedc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:12:21.468015Z",
     "iopub.status.busy": "2026-01-19T17:12:21.467815Z",
     "iopub.status.idle": "2026-01-19T17:12:55.163225Z",
     "shell.execute_reply": "2026-01-19T17:12:55.161897Z",
     "shell.execute_reply.started": "2026-01-19T17:12:21.467999Z"
    }
   },
   "outputs": [],
   "source": [
    "end_date = datetime.strptime(END_DATE, '%Y-%m-%d').replace(day=1) - relativedelta(months=1) # first day of the last completed month\n",
    "\n",
    "start_date = end_date - relativedelta(months=lookback_months)\n",
    "\n",
    "years_needed = set()\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    years_needed.add(current.year)\n",
    "    current += relativedelta(months=1)\n",
    "\n",
    "years_needed = sorted(years_needed)\n",
    "column_names = ['ZTIME', 'LON', 'LAT', 'WSR_ID', 'CELL_ID', 'RANGE', 'AZIMUTH', 'SEVPROB', 'PROB', 'MAXSIZE']\n",
    "\n",
    "dfs = []\n",
    "for year in years_needed:\n",
    "    s3_uri = f\"s3://noaa-swdi-pds/hail-{year}.csv\"\n",
    "    df = sedona.read.option(\"comment\", \"#\")\\\n",
    "        .csv(s3_uri)\\\n",
    "        .toDF(*column_names)\\\n",
    "        .withColumn(\"ZTIME\", to_timestamp(col(\"ZTIME\"), \"yyyyMMddHHmmss\"))\\\n",
    "        .withColumn(\"geometry\", expr(\"ST_Point(LON, LAT)\"))\n",
    "    dfs.append(df)\n",
    "\n",
    "hail_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    hail_df = hail_df.union(df)\n",
    "\n",
    "hail_df = hail_df.filter(\n",
    "    (col(\"ZTIME\") >= start_date) & (col(\"ZTIME\") <= end_date)\n",
    ")\n",
    "\n",
    "hail_df.createOrReplaceTempView(\"hail_staging\")\n",
    "\n",
    "# upsert assuming sevprob, prob and maxsize can change for entries in the past 3 months\n",
    "sedona.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{DATABASE}.hail_raw AS target\n",
    "    USING (\n",
    "        SELECT * FROM (\n",
    "            SELECT *,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY ZTIME, LON, LAT, WSR_ID, CELL_ID \n",
    "                    ORDER BY ZTIME\n",
    "                ) AS rn\n",
    "            FROM hail_staging\n",
    "        ) WHERE rn = 1\n",
    "    ) AS source\n",
    "    ON target.ZTIME = source.ZTIME \n",
    "       AND target.LON = source.LON \n",
    "       AND target.LAT = source.LAT\n",
    "       AND target.WSR_ID = source.WSR_ID\n",
    "       AND target.CELL_ID = source.CELL_ID\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        SEVPROB = source.SEVPROB,\n",
    "        PROB = source.PROB,\n",
    "        MAXSIZE = source.MAXSIZE\n",
    "    WHEN NOT MATCHED THEN INSERT (\n",
    "        ZTIME, LON, LAT, WSR_ID, CELL_ID, RANGE, AZIMUTH, \n",
    "        SEVPROB, PROB, MAXSIZE, geometry\n",
    "    ) VALUES (\n",
    "        source.ZTIME, source.LON, source.LAT, source.WSR_ID, source.CELL_ID, \n",
    "        source.RANGE, source.AZIMUTH, source.SEVPROB, source.PROB, \n",
    "        source.MAXSIZE, source.geometry\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ce016-aeef-4353-9646-12c899d52284",
   "metadata": {},
   "source": [
    "### Debug checking\n",
    "\n",
    "This will be a side task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8764e1-b998-404d-b6fd-74927e47142e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:12:57.407952Z",
     "iopub.status.busy": "2026-01-19T17:12:57.407734Z",
     "iopub.status.idle": "2026-01-19T17:13:02.276365Z",
     "shell.execute_reply": "2026-01-19T17:13:02.275647Z",
     "shell.execute_reply.started": "2026-01-19T17:12:57.407936Z"
    }
   },
   "outputs": [],
   "source": [
    "sedona.sql(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_records,\n",
    "        MIN(ZTIME) AS earliest_date,\n",
    "        MAX(ZTIME) AS latest_date,\n",
    "        COUNT(DISTINCT DATE(ZTIME)) AS unique_days,\n",
    "        COUNT(DISTINCT WSR_ID) AS unique_stations,\n",
    "        COUNT(CASE WHEN CAST(SEVPROB AS INT) = -999 THEN 1 END) AS missing_sevprob,\n",
    "        COUNT(CASE WHEN CAST(PROB AS INT) = -999 THEN 1 END) AS missing_prob,\n",
    "        COUNT(CASE WHEN CAST(MAXSIZE AS DOUBLE) = -999 THEN 1 END) AS missing_maxsize,\n",
    "        ROUND(AVG(NULLIF(CAST(MAXSIZE AS DOUBLE), -999)), 3) AS avg_hail_size,\n",
    "        MAX(NULLIF(CAST(MAXSIZE AS DOUBLE), -999)) AS max_hail_size\n",
    "    FROM {CATALOG}.{DATABASE}.hail_raw\n",
    "\"\"\").show(truncate=False)\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    SELECT DATE(ZTIME) AS date, COUNT(*) AS events\n",
    "    FROM {CATALOG}.{DATABASE}.hail_raw\n",
    "    GROUP BY DATE(ZTIME)\n",
    "    ORDER BY date DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()\n",
    "\n",
    "sedona.sql(f\"SELECT * FROM {CATALOG}.{DATABASE}.hail_raw LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b57714-bce0-4171-a0a3-cd1c02915314",
   "metadata": {},
   "source": [
    "## Get Overture Maps data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf74bb-2ac9-4ab2-be19-2091976ed696",
   "metadata": {},
   "source": [
    "### Create state boundary\n",
    "\n",
    "State based on the postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c23b7f-9eb1-46b5-8a32-13434ea6365d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:13:04.987658Z",
     "iopub.status.busy": "2026-01-19T17:13:04.987456Z",
     "iopub.status.idle": "2026-01-19T17:13:36.973079Z",
     "shell.execute_reply": "2026-01-19T17:13:36.971993Z",
     "shell.execute_reply.started": "2026-01-19T17:13:04.987641Z"
    }
   },
   "outputs": [],
   "source": [
    "sedona.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{DATABASE}.state_boundary AS target\n",
    "    USING (\n",
    "        SELECT \n",
    "            da.id,\n",
    "            d.names.primary AS state_name,\n",
    "            d.region AS state_code,\n",
    "            da.geometry\n",
    "        FROM wherobots_open_data.overture_maps_foundation.divisions_division d\n",
    "        JOIN wherobots_open_data.overture_maps_foundation.divisions_division_area da\n",
    "            ON d.id = da.division_id\n",
    "        WHERE d.subtype = 'region' \n",
    "          AND d.country = '{COUNTRY}'\n",
    "          AND d.region = CONCAT('{COUNTRY}-', (\n",
    "              SELECT address_levels[0].value\n",
    "              FROM wherobots_open_data.overture_maps_foundation.addresses_address\n",
    "              WHERE postcode = '{US_POSTCODE}' AND country = '{COUNTRY}'\n",
    "              LIMIT 1\n",
    "          ))\n",
    "        LIMIT 1\n",
    "    ) AS source\n",
    "    ON target.id = source.id\n",
    "    WHEN MATCHED THEN UPDATE SET \n",
    "        state_name = source.state_name,\n",
    "        state_code = source.state_code,\n",
    "        geometry = source.geometry\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"SELECT state_name, state_code FROM {CATALOG}.{DATABASE}.state_boundary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3d538-fa2d-43e7-b6ed-f28f99972b5b",
   "metadata": {},
   "source": [
    "### Creating the county area\n",
    "\n",
    "Based on the provided postcode. I tried neighborhood but the areas were too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d174f7b4-dbbd-4f93-99ab-7a756ed90108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:13:40.084034Z",
     "iopub.status.busy": "2026-01-19T17:13:40.083808Z",
     "iopub.status.idle": "2026-01-19T17:13:42.008764Z",
     "shell.execute_reply": "2026-01-19T17:13:42.007926Z",
     "shell.execute_reply.started": "2026-01-19T17:13:40.084018Z"
    }
   },
   "outputs": [],
   "source": [
    "# First check if the postcode exists  \n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    SELECT COUNT(*) as cnt\n",
    "    FROM wherobots_open_data.overture_maps_foundation.addresses_address\n",
    "    WHERE postcode = '{US_POSTCODE}' AND country = 'US'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783b072-aef5-4295-9066-77319854ff4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:13:43.848254Z",
     "iopub.status.busy": "2026-01-19T17:13:43.848055Z",
     "iopub.status.idle": "2026-01-19T17:13:54.910072Z",
     "shell.execute_reply": "2026-01-19T17:13:54.909112Z",
     "shell.execute_reply.started": "2026-01-19T17:13:43.848237Z"
    }
   },
   "outputs": [],
   "source": [
    "center = sedona.sql(f\"\"\"\n",
    "    SELECT ST_AsText(ST_Centroid(ST_Union_Aggr(geometry))) AS center_wkt\n",
    "    FROM wherobots_open_data.overture_maps_foundation.addresses_address\n",
    "    WHERE postcode = '{US_POSTCODE}' AND country = 'US'\n",
    "\"\"\").collect()[0]['center_wkt']\n",
    "\n",
    "sedona.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{DATABASE}.postcode_areas AS target\n",
    "    USING (\n",
    "        SELECT \n",
    "            '{US_POSTCODE}' AS postcode,\n",
    "            'US' AS country,\n",
    "            geometry AS area,\n",
    "            CURRENT_TIMESTAMP() AS created_at\n",
    "        FROM wherobots_open_data.overture_maps_foundation.divisions_division_area\n",
    "        WHERE country = 'US'\n",
    "          AND subtype = 'county'\n",
    "          AND ST_Contains(geometry, ST_GeomFromText('{center}'))\n",
    "        LIMIT 1\n",
    "    ) AS source\n",
    "    ON target.postcode = source.postcode AND target.country = source.country\n",
    "    WHEN MATCHED THEN UPDATE SET area = source.area, created_at = source.created_at\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d6cbf-9121-4a74-b655-81e814cce65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedona.sql(f\"\"\"\n",
    "    SELECT \n",
    "        '{US_POSTCODE}' as postcode,\n",
    "        da.names.primary as county_name,\n",
    "        ST_Area(ST_Transform(da.geometry, 'EPSG:4326', 'EPSG:3857')) / 2589988 as area_sqmi\n",
    "    FROM wherobots_open_data.overture_maps_foundation.divisions_division_area da\n",
    "    WHERE da.country = 'US'\n",
    "      AND da.subtype = 'county'\n",
    "      AND ST_Contains(da.geometry, ST_GeomFromText('{center}'))\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a9939-5840-4f79-8f08-394200706a14",
   "metadata": {},
   "source": [
    "## Subset the hail data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259cf7fa-dbe8-4c86-a3a6-dd18fbde843a",
   "metadata": {},
   "source": [
    "### Subset state first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4e148-cfc2-4444-9725-a7b730d52019",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedona.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{DATABASE}.hail_state AS target\n",
    "    USING (\n",
    "        SELECT h.*, s.state_code\n",
    "        FROM {CATALOG}.{DATABASE}.hail_raw h, {CATALOG}.{DATABASE}.state_boundary s\n",
    "        WHERE ST_Contains(s.geometry, h.geometry)\n",
    "    ) AS source\n",
    "    ON target.ZTIME = source.ZTIME \n",
    "       AND target.LON = source.LON \n",
    "       AND target.LAT = source.LAT\n",
    "       AND target.WSR_ID = source.WSR_ID\n",
    "       AND target.CELL_ID = source.CELL_ID\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        SEVPROB = source.SEVPROB,\n",
    "        PROB = source.PROB,\n",
    "        MAXSIZE = source.MAXSIZE\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a744d-9089-474c-a643-270c39824d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:15:59.616472Z",
     "iopub.status.busy": "2026-01-19T17:15:59.616250Z",
     "iopub.status.idle": "2026-01-19T17:16:00.873063Z",
     "shell.execute_reply": "2026-01-19T17:16:00.872136Z",
     "shell.execute_reply.started": "2026-01-19T17:15:59.616456Z"
    }
   },
   "outputs": [],
   "source": [
    "sedona.sql(f\"SELECT DISTINCT(state_code), COUNT(*) as state_hail_count FROM {CATALOG}.{DATABASE}.hail_state GROUP BY state_code\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bb962-b3c9-4462-b4c7-13725399a4c3",
   "metadata": {},
   "source": [
    "### Subset county\n",
    "\n",
    "I noticed some postcodes have no hail entries -> We can fail the Airflow task in this case and ask users to pick a different code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236224cb-0c17-4f4c-8de7-694223199500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:14:09.696488Z",
     "iopub.status.busy": "2026-01-19T17:14:09.696267Z",
     "iopub.status.idle": "2026-01-19T17:14:13.282433Z",
     "shell.execute_reply": "2026-01-19T17:14:13.281593Z",
     "shell.execute_reply.started": "2026-01-19T17:14:09.696472Z"
    }
   },
   "outputs": [],
   "source": [
    "sedona.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{DATABASE}.hail_neighborhood AS target\n",
    "    USING (\n",
    "        SELECT h.ZTIME, h.LON, h.LAT, h.WSR_ID, h.CELL_ID, h.RANGE, \n",
    "               h.AZIMUTH, h.SEVPROB, h.PROB, h.MAXSIZE, h.geometry,\n",
    "               p.postcode\n",
    "        FROM {CATALOG}.{DATABASE}.hail_state h, {CATALOG}.{DATABASE}.postcode_areas p\n",
    "        WHERE ST_Contains(p.area, h.geometry)\n",
    "          AND p.postcode = '{US_POSTCODE}'\n",
    "    ) AS source\n",
    "    ON target.ZTIME = source.ZTIME \n",
    "       AND target.LON = source.LON \n",
    "       AND target.LAT = source.LAT\n",
    "       AND target.postcode = source.postcode\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        SEVPROB = source.SEVPROB,\n",
    "        PROB = source.PROB,\n",
    "        MAXSIZE = source.MAXSIZE\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"SELECT count(*) FROM {CATALOG}.{DATABASE}.hail_neighborhood WHERE postcode = '{US_POSTCODE}'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e10e4e-a09f-45e3-a481-fa18ffba9da6",
   "metadata": {},
   "source": [
    "## Calculate comparison state vs neighborhood\n",
    "\n",
    "damaging_events = max_size > 1\n",
    "\n",
    "high_risk_events = sevprob > 50\n",
    "\n",
    "filters -999 as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c268b65-755b-45a2-866f-2086eef6bb27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:14:15.760403Z",
     "iopub.status.busy": "2026-01-19T17:14:15.760085Z",
     "iopub.status.idle": "2026-01-19T17:14:22.121106Z",
     "shell.execute_reply": "2026-01-19T17:14:22.120578Z",
     "shell.execute_reply.started": "2026-01-19T17:14:15.760386Z"
    }
   },
   "outputs": [],
   "source": [
    "sedona.sql(f\"\"\"\n",
    "    MERGE INTO {CATALOG}.{DATABASE}.risk_comparison AS target\n",
    "    USING (\n",
    "        WITH areas AS (\n",
    "            SELECT \n",
    "                p.postcode,\n",
    "                s.state_code,\n",
    "                ST_Area(ST_Transform(p.area, 'EPSG:4326', 'EPSG:3857')) / 2589988 AS neighborhood_area_sqmi,\n",
    "                ST_Area(ST_Transform(s.geometry, 'EPSG:4326', 'EPSG:3857')) / 2589988 AS state_area_sqmi\n",
    "            FROM {CATALOG}.{DATABASE}.postcode_areas p, {CATALOG}.{DATABASE}.state_boundary s\n",
    "            WHERE p.postcode = '{US_POSTCODE}'\n",
    "        ),\n",
    "        \n",
    "        neighborhood_stats AS (\n",
    "            SELECT \n",
    "                'neighborhood' AS area_type,\n",
    "                '{US_POSTCODE}' AS area_id,\n",
    "                COUNT(*) AS event_count,\n",
    "                AVG(NULLIF(CAST(MAXSIZE AS DOUBLE), -999)) AS avg_hail_size,\n",
    "                MAX(NULLIF(CAST(MAXSIZE AS DOUBLE), -999)) AS max_hail_size,\n",
    "                AVG(NULLIF(CAST(SEVPROB AS DOUBLE), -999)) AS avg_severe_prob,\n",
    "                AVG(NULLIF(CAST(PROB AS DOUBLE), -999)) AS avg_hail_prob,\n",
    "                COUNT(CASE WHEN NULLIF(CAST(MAXSIZE AS DOUBLE), -999) >= 1.0 THEN 1 END) AS damaging_events,\n",
    "                COUNT(CASE WHEN NULLIF(CAST(SEVPROB AS DOUBLE), -999) >= 50 THEN 1 END) AS high_risk_events\n",
    "            FROM {CATALOG}.{DATABASE}.hail_neighborhood\n",
    "            WHERE postcode = '{US_POSTCODE}'\n",
    "              AND ZTIME >= DATE_SUB(CURRENT_DATE(), 180)\n",
    "        ),\n",
    "        \n",
    "        state_stats AS (\n",
    "            SELECT \n",
    "                'state' AS area_type,\n",
    "                a.state_code AS area_id,\n",
    "                COUNT(*) AS event_count,\n",
    "                AVG(NULLIF(CAST(MAXSIZE AS DOUBLE), -999)) AS avg_hail_size,\n",
    "                MAX(NULLIF(CAST(MAXSIZE AS DOUBLE), -999)) AS max_hail_size,\n",
    "                AVG(NULLIF(CAST(SEVPROB AS DOUBLE), -999)) AS avg_severe_prob,\n",
    "                AVG(NULLIF(CAST(PROB AS DOUBLE), -999)) AS avg_hail_prob,\n",
    "                COUNT(CASE WHEN NULLIF(CAST(MAXSIZE AS DOUBLE), -999) >= 1.0 THEN 1 END) AS damaging_events,\n",
    "                COUNT(CASE WHEN NULLIF(CAST(SEVPROB AS DOUBLE), -999) >= 50 THEN 1 END) AS high_risk_events\n",
    "            FROM {CATALOG}.{DATABASE}.hail_state h, areas a\n",
    "            WHERE ZTIME >= DATE_SUB(CURRENT_DATE(), 180)\n",
    "            GROUP BY a.state_code\n",
    "        )\n",
    "        \n",
    "        SELECT \n",
    "            n.area_type,\n",
    "            n.area_id,\n",
    "            n.event_count,\n",
    "            ROUND(n.event_count / a.neighborhood_area_sqmi, 4) AS events_per_sqmi,\n",
    "            ROUND(n.avg_hail_size, 4) AS avg_hail_size,\n",
    "            n.max_hail_size,\n",
    "            ROUND(n.avg_severe_prob, 4) AS avg_severe_prob,\n",
    "            ROUND(n.avg_hail_prob, 4) AS avg_hail_prob,\n",
    "            n.damaging_events,\n",
    "            ROUND(n.damaging_events / a.neighborhood_area_sqmi, 4) AS damaging_per_sqmi,\n",
    "            n.high_risk_events,\n",
    "            ROUND(n.high_risk_events / a.neighborhood_area_sqmi, 4) AS high_risk_per_sqmi,\n",
    "            ROUND(a.neighborhood_area_sqmi, 4) AS area_sqmi,\n",
    "            CURRENT_TIMESTAMP() AS updated_at\n",
    "        FROM neighborhood_stats n, areas a\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT \n",
    "            s.area_type,\n",
    "            s.area_id,\n",
    "            s.event_count,\n",
    "            ROUND(s.event_count / a.state_area_sqmi, 4) AS events_per_sqmi,\n",
    "            ROUND(s.avg_hail_size, 4) AS avg_hail_size,\n",
    "            s.max_hail_size,\n",
    "            ROUND(s.avg_severe_prob, 4) AS avg_severe_prob,\n",
    "            ROUND(s.avg_hail_prob, 4) AS avg_hail_prob,\n",
    "            s.damaging_events,\n",
    "            ROUND(s.damaging_events / a.state_area_sqmi, 4) AS damaging_per_sqmi,\n",
    "            s.high_risk_events,\n",
    "            ROUND(s.high_risk_events / a.state_area_sqmi, 4) AS high_risk_per_sqmi,\n",
    "            ROUND(a.state_area_sqmi, 4) AS area_sqmi,\n",
    "            CURRENT_TIMESTAMP() AS updated_at\n",
    "        FROM state_stats s, areas a\n",
    "    ) AS source\n",
    "    ON target.area_type = source.area_type AND target.area_id = source.area_id\n",
    "    WHEN MATCHED THEN UPDATE SET *\n",
    "    WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\")\n",
    "\n",
    "sedona.sql(f\"SELECT * FROM {CATALOG}.{DATABASE}.risk_comparison\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb98f173-b83f-4c27-b4ab-9181e68f2ec4",
   "metadata": {},
   "source": [
    "## Calculate premium adjustment\n",
    "\n",
    "The idea is to have this run in Airflow s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45799ea2-2881-4fbc-8c6c-d47f9614e6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:19:00.955913Z",
     "iopub.status.busy": "2026-01-19T17:19:00.955695Z",
     "iopub.status.idle": "2026-01-19T17:19:02.588532Z",
     "shell.execute_reply": "2026-01-19T17:19:02.587906Z",
     "shell.execute_reply.started": "2026-01-19T17:19:00.955895Z"
    }
   },
   "outputs": [],
   "source": [
    "risk_df = sedona.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {CATALOG}.{DATABASE}.risk_comparison\n",
    "    WHERE area_id IN ('{US_POSTCODE}', (SELECT state_code FROM {CATALOG}.{DATABASE}.state_boundary LIMIT 1))\n",
    "\"\"\").toPandas()\n",
    "\n",
    "risk_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd5b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood = risk_df[risk_df['area_type'] == 'neighborhood'].iloc[0]\n",
    "state = risk_df[risk_df['area_type'] == 'state'].iloc[0]\n",
    "frequency_ratio = neighborhood['events_per_sqmi'] / state['events_per_sqmi']\n",
    "size_ratio = neighborhood['avg_hail_size'] / state['avg_hail_size']\n",
    "severity_ratio = neighborhood['avg_severe_prob'] / state['avg_severe_prob']\n",
    "damaging_ratio = neighborhood['damaging_per_sqmi'] / state['damaging_per_sqmi']\n",
    "\n",
    "weights = {\n",
    "    'frequency': 0.25,\n",
    "    'size': 0.25,\n",
    "    'severity': 0.25,\n",
    "    'damaging': 0.25\n",
    "}\n",
    "\n",
    "risk_score = (\n",
    "    weights['frequency'] * frequency_ratio +\n",
    "    weights['size'] * size_ratio +\n",
    "    weights['severity'] * severity_ratio +\n",
    "    weights['damaging'] * damaging_ratio\n",
    ")\n",
    "\n",
    "# Premium adjustment (1.0 = state average, >1 = increase, <1 = decrease)\n",
    "# Scale: 10% adjustment per 0.5 deviation from 1.0\n",
    "premium_modifier_pct = (risk_score - 1.0) * 20\n",
    "\n",
    "print(f\"=== Insurance Premium Analysis for {US_POSTCODE} ===\")\n",
    "print(f\"\\nRisk Ratios (vs State Average):\")\n",
    "print(f\"  Frequency:  {frequency_ratio:.2f}x\")\n",
    "print(f\"  Hail Size:  {size_ratio:.2f}x\")\n",
    "print(f\"  Severity:   {severity_ratio:.2f}x\")\n",
    "print(f\"  Damaging:   {damaging_ratio:.2f}x\")\n",
    "print(f\"\\nCombined Risk Score: {risk_score:.2f}\")\n",
    "print(f\"  (1.0 = state average)\")\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(f\"PREMIUM ADJUSTMENT: {premium_modifier_pct:+.1f}%\")\n",
    "print(f\"{'='*40}\")\n",
    "\n",
    "if premium_modifier_pct > 0:\n",
    "    print(f\"\\nHigher risk than state average - premium increase recommended\")\n",
    "else:\n",
    "    print(f\"\\nLower risk than state average - discount eligible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab24c14-0cc4-4036-85bf-a26e356adb39",
   "metadata": {},
   "source": [
    "## Viz\n",
    "\n",
    "I was thinking the date with the most hail in the neighborhood visualized for the whole state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b1482-09d2-4fe2-b623-eb9f750b00e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T17:16:22.519893Z",
     "iopub.status.busy": "2026-01-19T17:16:22.519670Z",
     "iopub.status.idle": "2026-01-19T17:16:31.253070Z",
     "shell.execute_reply": "2026-01-19T17:16:31.252196Z",
     "shell.execute_reply.started": "2026-01-19T17:16:22.519872Z"
    }
   },
   "outputs": [],
   "source": [
    "from sedona.spark.maps.SedonaKepler import SedonaKepler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "worst_day = sedona.sql(f\"\"\"\n",
    "    SELECT \n",
    "        DATE(ZTIME) as date,\n",
    "        COUNT(*) as event_count,\n",
    "        MAX(NULLIF(CAST(MAXSIZE AS DOUBLE), -999)) as max_size\n",
    "    FROM {CATALOG}.{DATABASE}.hail_neighborhood\n",
    "    WHERE postcode = '{US_POSTCODE}'\n",
    "    GROUP BY DATE(ZTIME)\n",
    "    ORDER BY max_size DESC, event_count DESC\n",
    "    LIMIT 1\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "worst_date = worst_day['date']\n",
    "\n",
    "state_hail_worst_day_df = sedona.sql(f\"\"\"\n",
    "    SELECT \n",
    "        ZTIME,\n",
    "        CAST(LON AS DOUBLE) as LON,\n",
    "        CAST(LAT AS DOUBLE) as LAT,\n",
    "        CAST(MAXSIZE AS DOUBLE) as MAXSIZE,\n",
    "        CAST(SEVPROB AS DOUBLE) as SEVPROB,\n",
    "        CAST(PROB AS DOUBLE) as PROB,\n",
    "        geometry,\n",
    "        DATE(ZTIME) as date\n",
    "    FROM {CATALOG}.{DATABASE}.hail_state\n",
    "    WHERE DATE(ZTIME) = '{worst_date}'\n",
    "\"\"\")\n",
    "\n",
    "state_boundary = sedona.sql(f\"SELECT state_code FROM {CATALOG}.{DATABASE}.state_boundary\").collect()[0]['state_code']\n",
    "\n",
    "counties_df = sedona.table(\"wherobots_open_data.overture_maps_foundation.divisions_division_area\")\\\n",
    "    .where(col(\"subtype\") == \"county\")\\\n",
    "    .where(col(\"region\") == state_boundary)\\\n",
    "    .select(\"geometry\", col(\"names.primary\").alias(\"county_name\"))\n",
    "\n",
    "county_name = sedona.sql(f\"\"\"\n",
    "    SELECT da.names.primary as county_name\n",
    "    FROM wherobots_open_data.overture_maps_foundation.divisions_division_area da,\n",
    "         {CATALOG}.{DATABASE}.postcode_areas p\n",
    "    WHERE da.subtype = 'county' \n",
    "      AND da.country = 'US'\n",
    "      AND ST_Equals(da.geometry, p.area)\n",
    "      AND p.postcode = '{US_POSTCODE}'\n",
    "\"\"\").collect()\n",
    "\n",
    "county_label = county_name[0]['county_name'] if county_name else f\"County ({US_POSTCODE})\"\n",
    "\n",
    "selected_county_df = sedona.sql(f\"\"\"\n",
    "    SELECT area as geometry, postcode\n",
    "    FROM {CATALOG}.{DATABASE}.postcode_areas\n",
    "    WHERE postcode = '{US_POSTCODE}'\n",
    "\"\"\")\n",
    "\n",
    "map_config = {'version': 'v1', 'config': {'visState': {'filters': [], 'layers': [{'id': 'hail_layer', 'type': 'geojson', 'config': {'dataId': 'hail', 'label': f'Hail - {worst_date}', 'color': [255, 153, 31], 'columns': {'geojson': 'geometry'}, 'isVisible': True, 'visConfig': {'opacity': 0.8, 'radius': 10, 'filled': True, 'stroked': True}}, 'visualChannels': {'colorField': {'name': 'MAXSIZE', 'type': 'real'}, 'colorScale': 'quantile'}}, {'id': 'counties_layer', 'type': 'geojson', 'config': {'dataId': 'counties', 'label': 'Counties', 'color': [34, 63, 154], 'columns': {'geojson': 'geometry'}, 'isVisible': True, 'visConfig': {'opacity': 0.1, 'strokeOpacity': 0.3, 'thickness': 0.5, 'filled': False, 'stroked': True}}}, {'id': 'selected_county_layer', 'type': 'geojson', 'config': {'dataId': 'selected_county', 'label': county_label, 'color': [0, 255, 100], 'columns': {'geojson': 'geometry'}, 'isVisible': True, 'visConfig': {'opacity': 0.2, 'strokeOpacity': 1.0, 'thickness': 3, 'strokeColor': [0, 255, 100], 'filled': True, 'stroked': True}}}]}, 'mapStyle': {'styleType': 'dark-matter'}}}\n",
    "\n",
    "worst_day_map = SedonaKepler.create_map(state_hail_worst_day_df, name=\"hail\", config=map_config)\n",
    "SedonaKepler.add_df(worst_day_map, counties_df, name=\"counties\")\n",
    "SedonaKepler.add_df(worst_day_map, selected_county_df, name=\"selected_county\")\n",
    "\n",
    "worst_day_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
